library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y=segmentationOriginal$Case, p=0.75, list = FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
set.seed(125)
Model.1 <- train(Case ~., method = "rpart", data = training)
plot(Model.1$finalModel, uniform = TRUE)
text(Model.1$finalModel, use.n = TRUE, all = TRUE, cex = .8)
View(segmentationOriginal)
Model.1 <- train(Class ~., method = "rpart", data = training)
plot(Model.1$finalModel, uniform = TRUE)
text(Model.1$finalModel, use.n = TRUE, all = TRUE, cex = .8)
print(Model.1$finalModel)
library(pgmm)
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
View(olive)
View(olive)
Model.2 <- train(Area ~., method = "rpart", data = olive)
newdata = as.data.frame(t(colMeans(olive)))
predict(Model.2, newdata = newdata)
library(ElemStatLearn)
install.packages("ElemStatLearn")
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
View(trainSA)
View(trainSA)
summary(SAheart)
head(SAheart)
Model.1 <- train(chd ~ age + alcohol + obesity + tobaco + typea + IdI, method = "glm", family="binomial")
library("caret", lib.loc="~/Library/R/3.4/library")
Model.1 <- train(chd ~ age + alcohol + obesity + tobaco + typea + IdI, method = "glm", family="binomial")
?train
Model.1 <- train(chd ~ age + alcohol + obesity + tobaco + typea + IdI, data = trainSA, method = "glm", family="binomial")
Model.1 <- train(chd ~ age + alcohol + obesity + tobacco + typea + IdI, data = trainSA, method = "glm", family="binomial")
Model.1 <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data = trainSA, method = "glm", family="binomial")
n.perdiction <- predict(Model.1, newdata = trainSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd, n.prediction)
missClass( trainSA$chd, n.perdiction )
nt.perdiction <- predict(Model.1, newdata = testSA)
missClass( testSA$chd, nt.perdiction )
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
install.packages("randomForest")
library("randomForest", lib.loc="~/Library/R/3.4/library")
randomForest(y ~., data = vowel.train)
t <- randomForest(y ~., data = vowel.train)
varImp(t)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
summary(vowel.train)
vowel.test$y <- as.factor(vowel.test$y)
vowel.train$y <- as.factor(vowel.train$y)
set.seed(33833)
library("caret", lib.loc="~/Library/R/3.4/library")
?train
fit.1 <- train(y ~. , data = vowel.train, method = 'rf')
fit.2 <- train(y ~., data = vowel.train, method = 'gbm')
print(fit.1)
print(fit.2)
predict.fit.1 <- predict(fit.1, vowel.test)
predict.fit.2 <- predict(fit.2, vowel.test)
acc.fit.1 <- sum(predict.fit.1 == vowel.test$y) / length(predict.fit.1)
acc.fit.2 <- sum(predict.fit.2 == vowel.test$y) / length(predict.fit.2)
agreeSub = vowel.test[pred_tree == pred_gbm,]
agreeSub = vowel.test[predict.fit.1 == predict.fit.2,]
View(agreeSub)
pred_comb = predict(predict.fit.1, agreeSub)
pred_comb = predict(fit.1, agreeSub)
comb_accuracy = sum(pred_comb == agreeSub$y) / length(pred_comb)
View(agreeSub)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
View(training)
fit.1 <- train(diagnosis ~ ., data = training, method = 'rf')
fit.2 <- train(diagnosis ~ ., data = training, method = 'gbm')
fit.3 <- train(diagnosis ~ ., data = training, method = 'lda')
pred.1 <- predict(fit.1, data = testing)
pred.2 <- predict(fit.1, data = testing)
pred.2 <- predict(fit.2, data = testing)
pred.3 <- predict(fit.3, data = testing)
predcomb <- data.frame(pred.1, pred.2, pred.3, diagnosis = training$diagnosis)
fit.comb <- train(diagnosis ~ ., method = 'rf', data = predcomb)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
fit.1 <- train(diagnosis ~ ., data = training, method = 'rf')
fit.1 <- train(diagnosis ~ ., data = training, method = 'gbm')
fit.1 <- train(diagnosis ~ ., data = training, method = 'rf')
fit.2 <- train(diagnosis ~ ., data = training, method = 'gbm', verbose = FALSE)
fit.3 <- train(diagnosis ~ ., data = training, method = 'lda', verbose = FALSE)
pred.1 <- predict(fit.1, testing)
pred.2 <- predict(fit.2, testing)
pred.3 <- predict(fit.3, testing)
predCB <- data.frame(pred.1, pred.2, pred.3, diagnosis = testing$diagnosis)
fit.CB <- train(diagnosis ~ ., data = predCB, method = 'rf')
pred.cb <- predict(fit.CB, data = predCB)
sqrt(sum((pred.cb - predCB$diagnosis)^2))
dim(pred.cb[pred.cb == predCB$diagnosis])
pred.cb[pred.cb == predCB$diagnosis]
lengh(pred.cb[pred.cb == predCB$diagnosis])
length(pred.cb[pred.cb == predCB$diagnosis])
length(predCB$diagnosis)
a.CB <- length(pred.cb[pred.cb == predCB$diagnosis])/length(predCB$diagnosis)
a.1 <- length(pred.cb[pred.1 == testing$diagnosis])/length(pred.1)
a.2 <- length(pred.cb[pred.2 == testing$diagnosis])/length(pred.2)
a.3 <- length(pred.cb[pred.3 == testing$diagnosis])/length(pred.3)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
fit.laaso <- train(CompressiveStreigth ~ ., data = training, method = 'lasso')
View(training)
View(training)
fit.laaso <- train(CompressiveStrength ~ ., data = training, method = 'lasso')
View(fit.laaso)
View(fit.laaso)
summary(fit.laaso)
?plot.enet
plot(fit.laaso, xvar = c("fraction", "penalty", "L1norm", "step"))
plot(fit.laaso, xvar = c( "penalty"))
plot.enet(fit.laaso, xvar = c( "penalty"))
plot(fit.laaso$finalModel, xvar = c( "penalty"))
plot.enet(fit.laaso$finalModel, xvar = c( "penalty"), use.color = TRUE)
library(caret)
plot.enet(fit.laaso$finalModel, xvar = c( "penalty"), use.color = TRUE)
library("elasticnet", lib.loc="~/Library/R/3.4/library")
plot.enet(fit.laaso$finalModel, xvar = c( "penalty"), use.color = TRUE)
library(lubridate) # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
install.packages("forecast")
?bats
library("forecast", lib.loc="~/Library/R/3.4/library")
?bats
visits.exp.smoothing = bats(tstrain)
library(lubridate)
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
visits.exp.smoothing = bats(tstrain)
visits.forecast = forecast(visits.exp.smoothing, nrow(testing))
plot(visits.forecast)
visits.forecast.lower95 = visits.forecast$lower[,2]
visits.forecast.upper95 = visits.forecast$upper[,2]
table (
(testing$visitsTumblr>visits.forecast.lower95) &
(testing$visitsTumblr<visits.forecast.upper95))
226/nrow(testing)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
library(caret)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain, ]
set.seed(325)
library(e1071)
mod_svm <- svm(CompressiveStrength ~ ., data = training)
pred_svm <- predict(mod_svm, testing)
accuracy(pred_svm, testing$CompressiveStrength)
library(forecast)
accuracy(pred_svm, testing$CompressiveStrength)
knitr::opts_chunk$set(echo = TRUE)
setwd("/Users/i312190/Desktop/Data Science/Unit 8/")
library("caret", lib.loc="~/Library/R/3.4/library")
setwd("/Users/i312190/Desktop/Data Science/Unit 8/")
library("caret", lib.loc="~/Library/R/3.4/library")
setwd("/Users/i312190/Desktop/Data Science/Unit 8/")
library("caret", lib.loc="~/Library/R/3.4/library")
raw.test <- read.csv("pml-testing.csv")
raw.train <- read.csv("pml-training.csv")
#What columns are useles Test
NA.Col.Test <- names(raw.test[, colMeans(is.na(raw.test)) >= 0.85])
#What columns are useles Train
NA.Col.Train <- names(raw.train[, colMeans(is.na(raw.train)) >= 0.85])
# Intersect useles columns
NA.Col.Res <- intersect( NA.Col.Test, NA.Col.Train)
#Exclude intersection from both datasets
start.test <- raw.test[, !names(raw.test) %in% NA.Col.Res]
start.train <- raw.train[, !names(raw.train) %in% NA.Col.Res]
#Exclude timestemp from both datasets
start.test <- start.test[, -c(3, 4, 5)]
start.train <- start.train[, -c(3, 4, 5)]
#Building data blocks
test.train <- createDataPartition(start.train$classe, p=0.75, list=FALSE)
start.train.train <- start.train[ test.train, ]
start.train.test <- start.train[ - test.train, ]
Tr.block <- trainControl(method = "cv", number = 2)
#classification tree
Cl.Tr.model <- train(classe ~ ., data = start.train.train, trControl = Tr.block, method="rpart")
# don't know maybe include plot here!!!!
cl.tr.predict <- predict(Cl.Tr.model, newdata = start.train.test )
cl.tr.confmatr <- confusionMatrix(start.train.test$classe, cl.tr.predict )
cl.tr.confmatr.acc <- cl.tr.confmatr$overall[1]
Cl.Tr.model  <- ''
Ran.for.model <- train(classe ~ ., data = start.train.train, trControl = Tr.block, method="rf")
Ran.for.model <- train(classe ~ ., data = start.train.train, trControl = Tr.block, method="rf", verbose = False)
Ran.for.model <- train(classe ~ ., data = start.train.train, method="rf", verbose = False)
system("defaults write org.R-project.R force.LANG en_US.UTF-8")
Sys.setenv(TZ="Europe/Moscow")
system("defaults write org.R-project.R force.LANG en_US.UTF-8")
Sys.setenv(TZ="Europe/Moscow")
setwd("/Users/i312190/Desktop/Data Science/Unit 8/")
library("caret", lib.loc="~/Library/R/3.4/library")
#-----
library(parallel)
library(doParallel)
#-----------
raw.test <- read.csv("pml-testing.csv")
raw.train <- read.csv("pml-training.csv")
#What columns are useles Test
NA.Col.Test <- names(raw.test[, colMeans(is.na(raw.test)) >= 0.85])
#What columns are useles Train
NA.Col.Train <- names(raw.train[, colMeans(is.na(raw.train)) >= 0.85])
NA.Col.Res <- unique(c(NA.Col.Test,NA.Col.Train ))
#-----------------
# Intersect useles columns
#NA.Col.Res <- intersect( NA.Col.Test, NA.Col.Train)
#------------------
#Exclude intersection from both datasets
start.test <- raw.test[, !names(raw.test) %in% NA.Col.Res]
start.train <- raw.train[, !names(raw.train) %in% NA.Col.Res]
#Exclude timestemp from both datasets
start.test <- start.test[, -c(3, 4, 5)]
start.train <- start.train[, -c(3, 4, 5)]
unlink('~/Desktop/Data Science/Unit 8/Course Project_cache', recursive = TRUE)
unlink('~/Desktop/Data Science/Unit 8/Course Project_cache', recursive = TRUE)
raw.test <- read.csv("pml-testing.csv")
raw.train <- read.csv("pml-training.csv")
#What columns are useles Test
NA.Col.Test <- names(raw.test[, colMeans(is.na(raw.test)) >= 0.85])
#What columns are useles Train
NA.Col.Train <- names(raw.train[, colMeans(is.na(raw.train)) >= 0.85])
NA.Col.Res <- unique(c(NA.Col.Test,NA.Col.Train ))
#-----------------
# Intersect useles columns
#NA.Col.Res <- intersect( NA.Col.Test, NA.Col.Train)
#------------------
#Exclude intersection from both datasets
start.test <- raw.test[, !names(raw.test) %in% NA.Col.Res]
start.train <- raw.train[, !names(raw.train) %in% NA.Col.Res]
#Exclude timestemp from both datasets
start.test <- start.test[, -c(3, 4, 5)]
start.train <- start.train[, -c(3, 4, 5)]
View(raw.test)
View(raw.test)
?qpot
?qplot
qplot
plot( raw.train$cvtd_timestamp, raw.train$classe)
?plot
plot( raw.train$cvtd_timestamp, raw.train$classe, main = 'Time & Classe correlation', xlab = 'Time', ylab = 'Classe')
plot( raw.train$cvtd_timestamp, raw.train$classe, main = 'Time & Classe correlation', xlab = 'Time', ylab = 'Classe')
unlink('~/Desktop/Data Science/Unit 8/Course Project T_cache', recursive = TRUE)
unlink('~/Desktop/Data Science/Unit 8/Course Project T_cache', recursive = TRUE)
setwd("/Users/i312190/Desktop/Data Science/Unit 8/")
unlink('Course Project T_cache', recursive = TRUE)
knitr::opts_chunk$set(cache=TRUE, message=FALSE, results = 'hide', warning = FALSE)
system("defaults write org.R-project.R force.LANG en_US.UTF-8")
Sys.setenv(TZ="Europe/Moscow")
setwd("/Users/i312190/Desktop/Data Science/Unit 8/")
library(caret)
#-----
library(parallel)
library(doParallel)
library(lattice)
library(ggplot2)
library(foreach)
library(iterators)
#-----------
raw.test <- read.csv("pml-testing.csv")
raw.train <- read.csv("pml-training.csv")
#What columns are useles Test
NA.Col.Test <- names(raw.test[, colMeans(is.na(raw.test)) >= 0.50])
#What columns are useles Train
NA.Col.Train <- names(raw.train[, colMeans(is.na(raw.train)) >= 0.50])
NA.Col.Res <- unique(c(NA.Col.Test,NA.Col.Train ))
#-----------------
# Intersect useles columns
#NA.Col.Res <- intersect( NA.Col.Test, NA.Col.Train)
#------------------
#Exclude intersection from both datasets
start.test <- raw.test[, !names(raw.test) %in% NA.Col.Res]
start.train <- raw.train[, !names(raw.train) %in% NA.Col.Res]
#Exclude timestemp from both datasets
start.test <- start.test[, -c(3, 4, 5)]
start.train <- start.train[, -c(3, 4, 5)]
#plotting correlation
plot( raw.train$cvtd_timestamp, raw.train$classe, main = 'Time & Classe correlation', xlab = 'Time', ylab = 'Classe')
#Building data blocks
test.train <- createDataPartition(start.train$classe, p=0.75, list=FALSE)
start.train.train <- start.train[ test.train, ]
start.train.test <- start.train[ - test.train, ]
Tr.block <- trainControl(method = "cv", allowParallel = TRUE, number = 5)
#classification tree
#---- Parallel execution start
cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)
#----
Cl.Tr.model <- train(classe ~ ., data = start.train.train, trControl = Tr.block, method="rpart")
#
#--------Parallel execution stop
stopCluster(cluster)
registerDoSEQ()
#-----------
cl.tr.predict <- predict(Cl.Tr.model, newdata = start.train.test )
cl.tr.confmatr <- confusionMatrix(start.train.test$classe, cl.tr.predict )
cl.tr.confmatr$overall
cl.tr.confmatr.acc <- cl.tr.confmatr$overall[1]
#random forest
#--------Parallel execution start
cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)
#-------------
Ran.for.model <- train(classe ~ ., data = start.train.train, trControl = Tr.block, method="rf", verbose = FALSE)
#-----Parallel execution stop
stopCluster(cluster)
registerDoSEQ()
#____
Ran.for.predict <- predict(Ran.for.model, newdata = start.train.test )
Ran.for.confmatr <- confusionMatrix(start.train.test$classe, Ran.for.predict )
Ran.for.confmatr$overall
ran.for.confmatr.acc <- Ran.for.confmatr$overall[1]
#Variable names
#names(Ran.for.model$finalModel)
dim(start.test)
print(Ran.for.model)
#Gradient boosting
Gr.B.model <- train(classe ~ ., data = start.train.train, trControl = Tr.block, method="gbm", verbose = FALSE)
GR.B.predict <- predict(Gr.B.model, newdata = start.train.test )
Gr.B.confmatr <- confusionMatrix(start.train.test$classe, GR.B.predict )
Gr.B.confmatr.acc <- Gr.B.confmatr$overall[1]
Gr.B.confmatr$overall
f.p.ds <- data.frame(cl.tr.predict, Ran.for.predict, GR.B.predict, start.train.test$classe )
un.model <- train(classe ~ ., data = start.train.test, method="gam", verbose = FALSE)
f.p.ds <- data.frame(cl.tr.predict, Ran.for.predict, GR.B.predict, start.train.test$classe )
un.model <- train(classe ~ ., data = start.train.test, method="rf", verbose = FALSE, trControl = Tr.block)
un.predict <- predict(un.model, f.p.ds)
f.p.ds <- data.frame(cl.tr.predict, Ran.for.predict, GR.B.predict, start.train.test$classe )
un.model <- train(classe ~ ., data = start.train.test, method="rf", verbose = FALSE, trControl = Tr.block)
un.predict <- predict(un.model, f.p.ds)
f.p.ds <- data.frame(cl.tr.predict, Ran.for.predict, GR.B.predict, start.train.test$classe )
un.model <- train(classe ~ ., data = start.train.test, method="rf", verbose = FALSE, trControl = Tr.block)
un.predict <- predict(un.model, f.p.ds$start.train.test.classe)
un.predict <- predict(f.p.ds$start.train.test.classe, un.model)
f.p.ds <- data.frame(cl.tr.predict, Ran.for.predict, GR.B.predict, classe = start.train.test$classe )
un.model <- train(classe ~ ., data = start.train.test, method="rf", verbose = FALSE, trControl = Tr.block)
un.predict <- predict(un.model, f.p.ds$classe)
f.p.ds <- data.frame(cl.tr.predict, Ran.for.predict, GR.B.predict, classe = start.train.test$classe )
un.model <- train(classe ~ ., data = f.p.ds, method="rf", verbose = FALSE, trControl = Tr.block)
un.predict <- predict(un.model, f.p.ds$classe)
un.confmatr <- confusionMatrix(start.train.test$classe, un.predict )
un.confmatr$overal
knitr::opts_chunk$set(cache=TRUE, message=FALSE, results = 'hide', warning = FALSE)
system("defaults write org.R-project.R force.LANG en_US.UTF-8")
Sys.setenv(TZ="Europe/Moscow")
setwd("/Users/i312190/Desktop/Data Science/Unit 8/")
library(caret)
#-----
library(parallel)
library(doParallel)
library(lattice)
library(ggplot2)
library(foreach)
library(iterators)
#-----------
raw.test <- read.csv("pml-testing.csv")
raw.train <- read.csv("pml-training.csv")
#What columns are useles Test
NA.Col.Test <- names(raw.test[, colMeans(is.na(raw.test)) >= 0.50])
#What columns are useles Train
NA.Col.Train <- names(raw.train[, colMeans(is.na(raw.train)) >= 0.50])
NA.Col.Res <- unique(c(NA.Col.Test,NA.Col.Train ))
#-----------------
# Intersect useles columns
#NA.Col.Res <- intersect( NA.Col.Test, NA.Col.Train)
#------------------
#Exclude intersection from both datasets
start.test <- raw.test[, !names(raw.test) %in% NA.Col.Res]
start.train <- raw.train[, !names(raw.train) %in% NA.Col.Res]
#Exclude timestemp, name and ID from both datasets
start.test <- start.test[, -c(1, 2, 3, 4, 5, 6)]
start.train <- start.train[, -c(1, 2, 3, 4, 5, 6)]
#plotting correlation
plot( raw.train$cvtd_timestamp, raw.train$classe, main = 'Time & Classe correlation', xlab = 'Time', ylab = 'Classe')
#Building data blocks
test.train <- createDataPartition(start.train$classe, p=0.75, list=FALSE)
start.train.train <- start.train[ test.train, ]
start.train.test <- start.train[ - test.train, ]
Tr.block <- trainControl(method = "cv", allowParallel = TRUE, number = 5)
#classification tree
#---- Parallel execution start
cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)
#----
Cl.Tr.model <- train(classe ~ ., data = start.train.train, trControl = Tr.block, method="rpart")
#
#--------Parallel execution stop
stopCluster(cluster)
registerDoSEQ()
#-----------
cl.tr.predict <- predict(Cl.Tr.model, newdata = start.train.test )
cl.tr.confmatr <- confusionMatrix(start.train.test$classe, cl.tr.predict )
cl.tr.confmatr$overall
cl.tr.confmatr.acc <- cl.tr.confmatr$overall[1]
#random forest
#--------Parallel execution start
cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)
#-------------
Ran.for.model <- train(classe ~ ., data = start.train.train, trControl = Tr.block, method="rf", verbose = FALSE)
#-----Parallel execution stop
stopCluster(cluster)
registerDoSEQ()
#____
Ran.for.predict <- predict(Ran.for.model, newdata = start.train.test )
Ran.for.confmatr <- confusionMatrix(start.train.test$classe, Ran.for.predict )
ran.for.confmatr.acc <- Ran.for.confmatr$overall[1]
#Variable names
#names(Ran.for.model$finalModel)
Ran.for.confmatr$overall[1]
#Gradient boosting
Gr.B.model <- train(classe ~ ., data = start.train.train, trControl = Tr.block, method="gbm", verbose = FALSE)
GR.B.predict <- predict(Gr.B.model, newdata = start.train.test )
Gr.B.confmatr <- confusionMatrix(start.train.test$classe, GR.B.predict )
Gr.B.confmatr.acc <- Gr.B.confmatr$overall[1]
#Gr.B.confmatr$overall[1]
Gr.B.confmatr$overall[1]
unlink('Course Project T_cache', recursive = TRUE)
